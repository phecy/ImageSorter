\documentclass[10pt,twocolumn]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\title{A Framework for Personalized Photograph Quality Assessment}
\author{
K. Armin Samii \\
ksamii@ucsc.edu
\and
Uliana Popov \\
uliana@soe.ucsc.edu}
\date{May 13, 2011}

\begin{document}
\maketitle
\begin{abstract}
Photograph quality assessment can help aid home users in managing their personal collections in several ways, including deleting low-quality images and browsing for high quality images. Recent research has aimed to automatically rate image quality, but such methods are far from perfect and progress is slow. In this paper, we propose a framework for quickly developing and testing new features to accelerate the progress of this research. We have two types of features: \textit{high-level features} are subjective qualities which humans can easily answer; \textit{low-level features} are objective calculations which are produced algorithmically. We use machine learning techniques to learn each of these separately. Our model allows for a developer to easily train new features (both low-level and high-level), and for an end-user to personalize which high-level features are important.

%First, we find how each high-level feature corresponds to overall image quality, allowing for user-adjusted preferences. Next, we find how the low-level features corresponds to each high-level feature. Finally, we allow both the low-level and high-level features to be dynamically adjusted by the developer with ease. We use basic Human Computation to obtain a ground truth.


\end{abstract}

\section{Problem Statement}
The first problem is to create a layer of abstraction for the end-user, who wants to modify the personal importance of high-level features without having to interpret the meaning of low-level features. The second is to allow a developer to continuously add features with ease. We will describe these problems in detail to make the specific purpose of this paper more clear.

\subsection{Abstraction from the end user}
This problem boils down to the following two questions:

\begin{enumerate}
\item \textbf{How important is each high-level feature to the overall rating of a photograph?}

This question is relevant to the end user. As an example:

%Photographers Penny and Quinn want to automatically rate their photographs so they can ignore those with low ratings and save some time when browsing their collections.
Penny takes pictures at concerts so she doesn't mind slightly underexposed images. Quinn takes pictures on racetracks so he is more lenient on how in-focus his image is. Penny will decrease the default weight on the high-level "exposure" feature. Quinn will do the same for "blur" weight.

\item \textbf{How does each low-level feature affect the ranking of a high-level feature?}

This  question is relevant to the developer. As an example:

Programmer Pete has several low-level features, such as the average width of edges and the average pixel color. She wants to use these low-level features to provide a rating for all high-level features. She cannot use them to directly influence the overall ranking because this would not allow the end-user photographers to adjust the weights of high-level features.
\end{enumerate}

\subsection{Ease of progress for the developer}
Say Programmer Pete finds a new way to measure blur levels in an image. He should be able to insert this feature into the program with ease. Because of the abstraction above, the end user would be unaware of any changes.

Instead, if Pete realizes that some new high-level feature is relevant to overall image quality (say, the saturation of the image), then he will want to see just how much saturation is relevant to image quality. The end-user photographers will be aware of this new change, and can adjust the high-level weights accordingly.

\section{Introduction}
In order to automatically asses an image quality, you have to 
evaluate its high-level features. %UUU: i'm lost here. low level or high level?
\begin{eqnarray}
I=\sum_{i=1}^N X_i*W_i
\end{eqnarray}
Where N is the number of features, X_i is value calculated by 
feature i, and W_i is a weight of feature i.

First, we use a logistic regression to calculate weights on which high-level features appeal to humans in photographs. We then use Support Vector Machines (SVMs) to match low-level features extracted algorithmically to high-level features. For example, the high level feature of "exposure" has more weight than "blur," and the low-level feature of "average pixel color" affects "exposure" more than it affects "blur." We then allow the weights of high-level features to be adjusted by users to allow personalization. The result is a rating of an image based on the base high-level weights and the user's individual preferences.

We keep a held-out test set to recalculate parameters when the developer adds a feature. When a new high-level feature is added, we ask Amazon Mechanical Turk\footnote{http://www.mturk.com} users ("Turkers") to rank an image based on that feature. When a low-level feature is added, the parameters of each of the SVMs are updated.

\section{Related Work}
Brian Barsky.

\section{Data}

There are two sets of data used, both of which are learned independently.

\subsection{User-Produced Data}
The initial set of data was produced by giving Turkers a simple statement for each high level feature, and asking if they agreed. Our primary, ground-truth statement for each image is:

``This image is high quality.''

We present this to five Turkers and ask them to choose one of three options, each of which corresponds to some number of points gained for each high-level feature:

\begin{itemize}
\item ``Agree'' (+1 point)
\item ``Neutral'' (+.5 points)
\item ``Disagree'' (+0 points)
\end{itemize}
The points are then averaged across the five Turkers' responses to come up with a final score.

We repeat this process for each high level feature, with statements such as ``This image is in focus'' and ``This image is well-exposed.'' The data then looks like:

\resizebox{7.5cm}{!}{
\begin{tabular}[t]{| c | c | c | c | l | }
 \hline
 & High Quality & In focus & Well exposed & \ldots \\ 
 \hline
Image 1 & .5 & .25 & 1 & \ldots \\ 
 \hline
\vdots & \vdots & \vdots & \vdots & $\ddots$ \\
 \hline
\end{tabular}
}

This data is used in a Logistic Regression to relate each high-level feature to the first statement (``This image is high-quality'').

\subsection{Application-produced data}
The application produces numbers for each high-level feature.

\section{Progress thus far}

\end{document}
